<html>
 <body>
  <p>
   Creates a panel of normals for read-count denoising
  </p>
  <h3>
   Category
   <small>
    Copy Number Variant Discovery
   </small>
  </h3>
  <hr/>
  <h2>
   Overview
  </h2>
  Creates a panel of normals (PoN) for read-count denoising given the read counts for samples in the panel.
 The resulting PoN can be used with DenoiseReadCounts to denoise other samples.
  <p>
   The input read counts are first transformed to log2 fractional coverages and preprocessed
     according to specified filtering and imputation parameters.  Singular value decomposition (SVD)
     is then performed to find the first number-of-eigensamples principal components,
     which are stored in the PoN.  Some or all of these principal components can then be used for
     denoising case samples with DenoiseReadCounts; it is assumed that the principal components used
     represent systematic sequencing biases (rather than statistical noise).  Examining the singular values,
     which are also stored in the PoN, may be useful in determining the appropriate number
     of principal components to use for denoising.
  </p>
  <p>
   If annotated intervals are provided, explicit GC-bias correction will be performed by GCBiasCorrector
     before filtering and SVD.  GC-content information for the intervals will be stored in the PoN
     and used to perform explicit GC-bias correction identically in DenoiseReadCounts.
     Note that if annotated intervals are not provided, it is still likely that GC-bias correction is
     implicitly performed by the SVD denoising process (i.e., some of the principal components arise from GC bias).
  </p>
  <p>
   Note that such SVD denoising cannot distinguish between variance due to systematic sequencing biases and that
     due to true common germline CNVs present in the panel; signal from the latter may thus be inadvertently denoised
     away.  Furthermore, variance arising from coverage on the sex chromosomes may also significantly contribute
     to the principal components if the panel contains samples of mixed sex.  Therefore, if sex chromosomes
     are not excluded from coverage collection, it is strongly recommended that users avoid creating panels of
     mixed sex and take care to denoise case samples only with panels containing only individuals of the same sex
     as the case samples.  (See GermlineCNVCaller, which avoids these issues by simultaneously learning
     a probabilistic model for systematic bias and calling rare and common germline CNVs for samples in the panel.)
  </p>
  <h3>
   Inputs
  </h3>
  <ul>
   <li>
    Counts files (TSV or HDF5 output of CollectReadCounts).
   </li>
   <li>
    (Optional) GC-content annotated-intervals file from AnnotateIntervals.
         Explicit GC-bias correction will be performed on the panel samples and identically for subsequent case samples.
   </li>
  </ul>
  <h3>
   Output
  </h3>
  <ul>
   <li>
    Panel-of-normals file.
         This is an HDF5 file containing the panel data in the paths defined in HDF5SVDReadCountPanelOfNormals.
         HDF5 files may be viewed using
    <a href="https://support.hdfgroup.org/products/java/hdfview/">
     hdfview
    </a>
    or loaded in python using
    <a href="http://www.pytables.org/">
     PyTables
    </a>
    or
    <a href="http://www.h5py.org/">
     h5py
    </a>
    .
   </li>
  </ul>
  <h3>
   Usage examples
  </h3>
  <pre>
     gatk CreateReadCountPanelOfNormals \
          -I sample_1.counts.hdf5 \
          -I sample_2.counts.hdf5 \
          ... \
          -O cnv.pon.hdf5
 </pre>
  <pre>
     gatk CreateReadCountPanelOfNormals \
          -I sample_1.counts.hdf5 \
          -I sample_2.counts.tsv \
          ... \
          --annotated-intervals annotated_intervals.tsv \
          -O cnv.pon.hdf5
 </pre>
  <h3>
   CreateReadCountPanelOfNormals specific arguments
  </h3>
  <p>
   This table summarizes the command-line arguments that are specific to this tool. For more details on each argument, see the list further down below the table or click on an argument name to jump directly to that entry in the list.
  </p>
  <table class="table table-striped table-bordered table-condensed cozy">
   <thead>
    <tr>
     <th>
      Argument name(s)
     </th>
     <th>
      Default value
     </th>
     <th>
      Summary
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <th colspan="4" id="row-divider">
      Required Arguments
     </th>
    </tr>
    <tr>
     <td>
      <a href="#--input">
       --input
      </a>
      <br/>
      <em>
       -I
      </em>
     </td>
     <!--<td>List[File]</td> -->
     <td>
     </td>
     <td>
      Input TSV or HDF5 files containing integer read counts in genomic intervals for all samples in the panel of normals (output of CollectReadCounts).  Intervals must be identical and in the same order for all samples.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--output">
       --output
      </a>
      <br/>
      <em>
       -O
      </em>
     </td>
     <!--<td>File</td> -->
     <td>
     </td>
     <td>
      Output file for the panel of normals.
     </td>
    </tr>
    <tr>
     <th colspan="4" id="row-divider">
      Optional Tool Arguments
     </th>
    </tr>
    <tr>
     <td>
      <a href="#--annotated-intervals">
       --annotated-intervals
      </a>
      <br/>
     </td>
     <!--<td>File</td> -->
     <td>
     </td>
     <td>
      Input file containing annotations for GC content in genomic intervals (output of AnnotateIntervals).  If provided, explicit GC correction will be performed before performing SVD.  Intervals must be identical to and in the same order as those in the input read-counts files.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--arguments_file">
       --arguments_file
      </a>
      <br/>
     </td>
     <!--<td>List[File]</td> -->
     <td>
     </td>
     <td>
      read one or more arguments files and add them to the command line
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--conf">
       --conf
      </a>
      <br/>
     </td>
     <!--<td>List[String]</td> -->
     <td>
     </td>
     <td>
      Spark properties to set on the Spark context in the format
      <property>
       =
       <value>
       </value>
      </property>
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--do-impute-zeros">
       --do-impute-zeros
      </a>
      <br/>
     </td>
     <!--<td>boolean</td> -->
     <td>
      true
     </td>
     <td>
      If true, impute zero-coverage values as the median of the non-zero values in the corresponding interval.  (This is applied after all filters.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--extreme-outlier-truncation-percentile">
       --extreme-outlier-truncation-percentile
      </a>
      <br/>
     </td>
     <!--<td>double</td> -->
     <td>
      0.1
     </td>
     <td>
      Fractional coverages normalized by genomic-interval medians that are strictly below this percentile or strictly above the complementary percentile are set to the corresponding percentile value.  (This is applied after all filters and imputation.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--extreme-sample-median-percentile">
       --extreme-sample-median-percentile
      </a>
      <br/>
     </td>
     <!--<td>double</td> -->
     <td>
      2.5
     </td>
     <td>
      Samples with a median (across genomic intervals) of fractional coverage normalized by genomic-interval medians  strictly below this percentile or strictly above the complementary percentile are filtered out.  (This is the fourth filter applied.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--gcs-max-retries">
       --gcs-max-retries
      </a>
      <br/>
      <em>
       -gcs-retries
      </em>
     </td>
     <!--<td>int</td> -->
     <td>
      20
     </td>
     <td>
      If the GCS bucket channel errors out, how many times it will attempt to re-initiate the connection
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--gcs-project-for-requester-pays">
       --gcs-project-for-requester-pays
      </a>
      <br/>
     </td>
     <!--<td>String</td> -->
     <td>
     </td>
     <td>
      Project to bill when accessing "requester pays" buckets. If unset, these buckets cannot be accessed.  User must have storage.buckets.get permission on the bucket being accessed.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--help">
       --help
      </a>
      <br/>
      <em>
       -h
      </em>
     </td>
     <!--<td>boolean</td> -->
     <td>
      false
     </td>
     <td>
      display the help message
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--maximum-zeros-in-interval-percentage">
       --maximum-zeros-in-interval-percentage
      </a>
      <br/>
     </td>
     <!--<td>double</td> -->
     <td>
      5.0
     </td>
     <td>
      Genomic intervals with a fraction of zero-coverage samples greater than or equal to this percentage are filtered out.  (This is the third filter applied.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--maximum-zeros-in-sample-percentage">
       --maximum-zeros-in-sample-percentage
      </a>
      <br/>
     </td>
     <!--<td>double</td> -->
     <td>
      5.0
     </td>
     <td>
      Samples with a fraction of zero-coverage genomic intervals greater than or equal to this percentage are filtered out.  (This is the second filter applied.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--minimum-interval-median-percentile">
       --minimum-interval-median-percentile
      </a>
      <br/>
     </td>
     <!--<td>double</td> -->
     <td>
      10.0
     </td>
     <td>
      Genomic intervals with a median (across samples) of fractional coverage (optionally corrected for GC bias) less than or equal to this percentile are filtered out.  (This is the first filter applied.)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--number-of-eigensamples">
       --number-of-eigensamples
      </a>
      <br/>
     </td>
     <!--<td>int</td> -->
     <td>
      20
     </td>
     <td>
      Number of eigensamples to use for truncated SVD and to store in the panel of normals.  The number of samples retained after filtering will be used instead if it is smaller than this.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--program-name">
       --program-name
      </a>
      <br/>
     </td>
     <!--<td>String</td> -->
     <td>
     </td>
     <td>
      Name of the program running
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--spark-master">
       --spark-master
      </a>
      <br/>
     </td>
     <!--<td>String</td> -->
     <td>
      local[*]
     </td>
     <td>
      URL of the Spark Master to submit jobs to when using the Spark pipeline runner.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--spark-verbosity">
       --spark-verbosity
      </a>
      <br/>
     </td>
     <!--<td>String</td> -->
     <td>
     </td>
     <td>
      Spark verbosity. Overrides --verbosity for Spark-generated logs only. Possible values: {ALL, DEBUG, INFO, WARN, ERROR, FATAL, OFF, TRACE}
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--version">
       --version
      </a>
      <br/>
     </td>
     <!--<td>boolean</td> -->
     <td>
      false
     </td>
     <td>
      display the version number for this tool
     </td>
    </tr>
    <tr>
     <th colspan="4" id="row-divider">
      Optional Common Arguments
     </th>
    </tr>
    <tr>
     <td>
      <a href="#--gatk-config-file">
       --gatk-config-file
      </a>
      <br/>
     </td>
     <!--<td>String</td> -->
     <td>
     </td>
     <td>
      A configuration file to use with the GATK.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--QUIET">
       --QUIET
      </a>
      <br/>
     </td>
     <!--<td>Boolean</td> -->
     <td>
      false
     </td>
     <td>
      Whether to suppress job-summary info on System.err.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--tmp-dir">
       --tmp-dir
      </a>
      <br/>
     </td>
     <!--<td>GATKPath</td> -->
     <td>
     </td>
     <td>
      Temp directory to use.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--use-jdk-deflater">
       --use-jdk-deflater
      </a>
      <br/>
      <em>
       -jdk-deflater
      </em>
     </td>
     <!--<td>boolean</td> -->
     <td>
      false
     </td>
     <td>
      Whether to use the JdkDeflater (as opposed to IntelDeflater)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--use-jdk-inflater">
       --use-jdk-inflater
      </a>
      <br/>
      <em>
       -jdk-inflater
      </em>
     </td>
     <!--<td>boolean</td> -->
     <td>
      false
     </td>
     <td>
      Whether to use the JdkInflater (as opposed to IntelInflater)
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--verbosity">
       --verbosity
      </a>
      <br/>
     </td>
     <!--<td>LogLevel</td> -->
     <td>
      INFO
     </td>
     <td>
      Control verbosity of logging.
     </td>
    </tr>
    <tr>
     <th colspan="4" id="row-divider">
      Advanced Arguments
     </th>
    </tr>
    <tr>
     <td>
      <a href="#--maximum-chunk-size">
       --maximum-chunk-size
      </a>
      <br/>
     </td>
     <!--<td>int</td> -->
     <td>
      16777215
     </td>
     <td>
      Maximum HDF5 matrix chunk size.  Large matrices written to HDF5 are chunked into equally sized subsets of rows (plus a subset containing the remainder, if necessary) to avoid a hard limit in Java HDF5 on the number of elements in a matrix.  However, since a single row is not allowed to be split across multiple chunks, the number of columns must be less than the maximum number of values in each chunk.  Decreasing this number will reduce heap usage when writing chunks.
     </td>
    </tr>
    <tr>
     <td>
      <a href="#--showHidden">
       --showHidden
      </a>
      <br/>
     </td>
     <!--<td>boolean</td> -->
     <td>
      false
     </td>
     <td>
      display hidden arguments
     </td>
    </tr>
   </tbody>
  </table>
  <h3>
   Argument details
  </h3>
  <p>
   Arguments in this list are specific to this tool. Keep in mind that other arguments are available that are shared with other tools (e.g. command-line GATK arguments); see Inherited arguments above.
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--annotated-intervals">
    --annotated-intervals
   </a>
  </h3>
  <p class="args">
   <b>
    Input file containing annotations for GC content in genomic intervals (output of AnnotateIntervals).  If provided, explicit GC correction will be performed before performing SVD.  Intervals must be identical to and in the same order as those in the input read-counts files.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    File
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--arguments_file">
    --arguments_file
   </a>
  </h3>
  <p class="args">
   <b>
    read one or more arguments files and add them to the command line
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    List[File]
   </span>
   <span class="label">
    []
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--conf">
    --conf
   </a>
  </h3>
  <p class="args">
   <b>
    Spark properties to set on the Spark context in the format
    <property>
     =
     <value>
     </value>
    </property>
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    List[String]
   </span>
   <span class="label">
    []
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--do-impute-zeros">
    --do-impute-zeros
   </a>
  </h3>
  <p class="args">
   <b>
    If true, impute zero-coverage values as the median of the non-zero values in the corresponding interval.  (This is applied after all filters.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    true
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--extreme-outlier-truncation-percentile">
    --extreme-outlier-truncation-percentile
   </a>
  </h3>
  <p class="args">
   <b>
    Fractional coverages normalized by genomic-interval medians that are strictly below this percentile or strictly above the complementary percentile are set to the corresponding percentile value.  (This is applied after all filters and imputation.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    double
   </span>
   <span class="label">
    0.1
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    50 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--extreme-sample-median-percentile">
    --extreme-sample-median-percentile
   </a>
  </h3>
  <p class="args">
   <b>
    Samples with a median (across genomic intervals) of fractional coverage normalized by genomic-interval medians  strictly below this percentile or strictly above the complementary percentile are filtered out.  (This is the fourth filter applied.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    double
   </span>
   <span class="label">
    2.5
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    50 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--gatk-config-file">
    --gatk-config-file
   </a>
  </h3>
  <p class="args">
   <b>
    A configuration file to use with the GATK.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    String
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--gcs-max-retries">
    --gcs-max-retries
   </a>
   /
   <small>
    -gcs-retries
   </small>
  </h3>
  <p class="args">
   <b>
    If the GCS bucket channel errors out, how many times it will attempt to re-initiate the connection
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    int
   </span>
   <span class="label">
    20
   </span>
   <span class="label label-warning">
    [ [ -∞
   </span>
   <span class="label label-warning">
    ∞ ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--gcs-project-for-requester-pays">
    --gcs-project-for-requester-pays
   </a>
  </h3>
  <p class="args">
   <b>
    Project to bill when accessing "requester pays" buckets. If unset, these buckets cannot be accessed.  User must have storage.buckets.get permission on the bucket being accessed.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    String
   </span>
   <span class="label">
    ""
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--help">
    --help
   </a>
   /
   <small>
    -h
   </small>
  </h3>
  <p class="args">
   <b>
    display the help message
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--input">
    --input
   </a>
   /
   <small>
    -I
   </small>
  </h3>
  <p class="args">
   <b>
    Input TSV or HDF5 files containing integer read counts in genomic intervals for all samples in the panel of normals (output of CollectReadCounts).  Intervals must be identical and in the same order for all samples.
   </b>
   <br/>
  </p>
  <p>
   <span class="badge badge-important">
    R
   </span>
   <span class="label label-info">
    List[File]
   </span>
   <span class="label">
    []
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--maximum-chunk-size">
    --maximum-chunk-size
   </a>
  </h3>
  <p class="args">
   <b>
    Maximum HDF5 matrix chunk size.  Large matrices written to HDF5 are chunked into equally sized subsets of rows (plus a subset containing the remainder, if necessary) to avoid a hard limit in Java HDF5 on the number of elements in a matrix.  However, since a single row is not allowed to be split across multiple chunks, the number of columns must be less than the maximum number of values in each chunk.  Decreasing this number will reduce heap usage when writing chunks.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    int
   </span>
   <span class="label">
    16777215
   </span>
   <span class="label label-warning">
    [ [ 1
   </span>
   <span class="label label-warning">
    268,435,455 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--maximum-zeros-in-interval-percentage">
    --maximum-zeros-in-interval-percentage
   </a>
  </h3>
  <p class="args">
   <b>
    Genomic intervals with a fraction of zero-coverage samples greater than or equal to this percentage are filtered out.  (This is the third filter applied.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    double
   </span>
   <span class="label">
    5.0
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    100 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--maximum-zeros-in-sample-percentage">
    --maximum-zeros-in-sample-percentage
   </a>
  </h3>
  <p class="args">
   <b>
    Samples with a fraction of zero-coverage genomic intervals greater than or equal to this percentage are filtered out.  (This is the second filter applied.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    double
   </span>
   <span class="label">
    5.0
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    100 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--minimum-interval-median-percentile">
    --minimum-interval-median-percentile
   </a>
  </h3>
  <p class="args">
   <b>
    Genomic intervals with a median (across samples) of fractional coverage (optionally corrected for GC bias) less than or equal to this percentile are filtered out.  (This is the first filter applied.)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    double
   </span>
   <span class="label">
    10.0
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    100 ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--number-of-eigensamples">
    --number-of-eigensamples
   </a>
  </h3>
  <p class="args">
   <b>
    Number of eigensamples to use for truncated SVD and to store in the panel of normals.  The number of samples retained after filtering will be used instead if it is smaller than this.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    int
   </span>
   <span class="label">
    20
   </span>
   <span class="label label-warning">
    [ [ 0
   </span>
   <span class="label label-warning">
    ∞ ] ]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--output">
    --output
   </a>
   /
   <small>
    -O
   </small>
  </h3>
  <p class="args">
   <b>
    Output file for the panel of normals.
   </b>
   <br/>
  </p>
  <p>
   <span class="badge badge-important">
    R
   </span>
   <span class="label label-info">
    File
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--program-name">
    --program-name
   </a>
  </h3>
  <p class="args">
   <b>
    Name of the program running
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    String
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--QUIET">
    --QUIET
   </a>
  </h3>
  <p class="args">
   <b>
    Whether to suppress job-summary info on System.err.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    Boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--showHidden">
    --showHidden
   </a>
   /
   <small>
    -showHidden
   </small>
  </h3>
  <p class="args">
   <b>
    display hidden arguments
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--spark-master">
    --spark-master
   </a>
  </h3>
  <p class="args">
   <b>
    URL of the Spark Master to submit jobs to when using the Spark pipeline runner.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    String
   </span>
   <span class="label">
    local[*]
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--spark-verbosity">
    --spark-verbosity
   </a>
  </h3>
  <p class="args">
   <b>
    Spark verbosity. Overrides --verbosity for Spark-generated logs only. Possible values: {ALL, DEBUG, INFO, WARN, ERROR, FATAL, OFF, TRACE}
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    String
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--tmp-dir">
    --tmp-dir
   </a>
  </h3>
  <p class="args">
   <b>
    Temp directory to use.
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    GATKPath
   </span>
   <span class="label">
    null
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--use-jdk-deflater">
    --use-jdk-deflater
   </a>
   /
   <small>
    -jdk-deflater
   </small>
  </h3>
  <p class="args">
   <b>
    Whether to use the JdkDeflater (as opposed to IntelDeflater)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--use-jdk-inflater">
    --use-jdk-inflater
   </a>
   /
   <small>
    -jdk-inflater
   </small>
  </h3>
  <p class="args">
   <b>
    Whether to use the JdkInflater (as opposed to IntelInflater)
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--verbosity">
    --verbosity
   </a>
   /
   <small>
    -verbosity
   </small>
  </h3>
  <p class="args">
   <b>
    Control verbosity of logging.
   </b>
   <br/>
  </p>
  <p>
   The --verbosity argument is an enumerated type (LogLevel), which can have one of the following values:
  </p>
  <dl class="enum">
   <dt class="enum">
    ERROR
   </dt>
   <dd class="enum">
   </dd>
   <dt class="enum">
    WARNING
   </dt>
   <dd class="enum">
   </dd>
   <dt class="enum">
    INFO
   </dt>
   <dd class="enum">
   </dd>
   <dt class="enum">
    DEBUG
   </dt>
   <dd class="enum">
   </dd>
  </dl>
  <p>
   <span class="label label-info">
    LogLevel
   </span>
   <span class="label">
    INFO
   </span>
  </p>
  <hr style="border-bottom: dotted 1px #C0C0C0;"/>
  <h3>
   <a name="--version">
    --version
   </a>
  </h3>
  <p class="args">
   <b>
    display the version number for this tool
   </b>
   <br/>
  </p>
  <p>
   <span class="label label-info">
    boolean
   </span>
   <span class="label">
    false
   </span>
  </p>
  <hr/>
  <p>
   <a href="#top">
    <i class="fa fa-chevron-up">
    </i>
    Return to top
   </a>
  </p>
  <hr/>
 </body>
</html>